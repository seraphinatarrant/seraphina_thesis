@inproceedings{sogaard2016deep,
  title={Deep multi-task learning with low level tasks supervised at lower layers},
  author={S{\o}gaard, Anders and Goldberg, Yoav},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  volume={2},
  pages={231--235},
  year={2016}
}
@article{kirov2018recurrent,
  title={Recurrent Neural Networks in Linguistic Theory: Revisiting Pinker and Prince (1988) and the Past Tense Debate},
  author={Kirov, Christo and Cotterell, Ryan},
  journal={arXiv preprint arXiv:1807.04783},
  year={2018}
}

@article{hupkes2018visualisation,
  title={Visualisation and'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure},
  author={Hupkes, Dieuwke and Veldhoen, Sara and Zuidema, Willem},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={907--926},
  year={2018}
}


@article{wieting2019no,
  title={No Training Required: Exploring Random Encoders for Sentence Classification},
  author={Wieting, John and Kiela, Douwe},
  journal={arXiv preprint arXiv:1901.10444},
  year={2019}
}


@article{vanmassenhove2017investigating,
  title={Investigating ‘Aspect’in NMT and SMT: Translating the English Simple Past and Present Perfect},
  author={Vanmassenhove, Eva and Du, Jinhua and Way, Andy},
  journal={Computational Linguistics in the Netherlands Journal},
  volume={7},
  pages={109--128},
  year={2017}
}

@article{cifka2018bleu,
  title={Are BLEU and Meaning Representation in Opposition?},
  author={C{\'\i}fka, Ond{\v{r}}ej and Bojar, Ond{\v{r}}ej},
  journal={arXiv preprint arXiv:1805.06536},
  year={2018}
}

@article{noshad_scalable_2018,
	title = {Scalable {Mutual} {Information} {Estimation} using {Dependence} {Graphs}},
	journal = {arXiv preprint arXiv:1801.09125},
	author = {Noshad, Morteza and Hero III, Alfred O.},
	year = {2018},
	file = {Full Text:/Users/nsaphra/Dropbox/zotero/storage/GCXBPDW3/Noshad and Hero III - 2018 - Scalable Mutual Information Estimation using Depen.pdf:application/pdf;Snapshot:/Users/nsaphra/Dropbox/zotero/storage/772TB8MZ/1801.html:text/html}
}

@inproceedings{kementchedjhieva2018indicatements,
  title={{\emph{Indicatements}} that character language models learn {E}nglish morpho-syntactic units and regularities},
  author={Kementchedjhieva, Yova and Lopez, Adam},
  booktitle={Proc. of Workshop on Analyzing and interpreting neural networks for NLP},
  year={2018}
}

@article{zhang_language_2018,
	title = {Language {Modeling} {Teaches} {You} {More} {Syntax} than {Translation} {Does}: {Lessons} {Learned} {Through} {Auxiliary} {Task} {Analysis}},
	shorttitle = {Language {Modeling} {Teaches} {You} {More} {Syntax} than {Translation} {Does}},
	url = {http://arxiv.org/abs/1809.10040},
	abstract = {Recent work using auxiliary prediction task classifiers to investigate the properties of LSTM representations has begun to shed light on why pretrained representations, like ELMo (Peters et al., 2018) and CoVe (McCann et al., 2017), are so beneficial for neural language understanding models. We still, though, do not yet have a clear understanding of how the choice of pretraining objective affects the type of linguistic information that models learn. With this in mind, we compare four objectives---language modeling, translation, skip-thought, and autoencoding---on their ability to induce syntactic and part-of-speech information. We make a fair comparison between the tasks by holding constant the quantity and genre of the training data, as well as the LSTM architecture. We find that representations from language models consistently perform best on our syntactic auxiliary prediction tasks, even when trained on relatively small amounts of data. These results suggest that language modeling may be the best data-rich pretraining task for transfer learning applications requiring syntactic information. We also find that the representations from randomly-initialized, frozen LSTMs perform strikingly well on our syntactic auxiliary tasks, but this effect disappears when the amount of training data for the auxiliary tasks is reduced.},
	urldate = {2018-10-02},
	journal = {arXiv:1809.10040 [cs]},
	author = {Zhang, Kelly W. and Bowman, Samuel R.},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.10040},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1809.10040 PDF:/Users/nsaphra/Documents/zotero/storage/QH9GDT6G/Zhang and Bowman - 2018 - Language Modeling Teaches You More Syntax than Tra.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/PN7QX56E/1809.html:text/html}
}

@article{tsvetkov_learning_2016,
	title = {Learning the {Curriculum} with {Bayesian} {Optimization} for {Task}-{Specific} {Word} {Representation} {Learning}},
	volume = {abs/1605.03852},
	journal = {CoRR},
	author = {Tsvetkov, Yulia and Faruqui, Manaal and Ling, Wang and MacWhinney, Brian and Dyer, Chris},
	year = {2016},
	file = {[PDF] from arxiv.org:/Users/nsaphra/Documents/zotero/storage/4WTF54HZ/Tsvetkov et al. - 2016 - Learning the Curriculum with Bayesian Optimization.pdf:application/pdf;Snapshot:/Users/nsaphra/Documents/zotero/storage/ARRFNTJB/1605.html:text/html}
}

@inproceedings{murdoch_beyond_2018,
	title = {Beyond {Word} {Importance}: {Contextual} {Decomposition} to {Extract} {Interactions} from {LSTMs}},
	shorttitle = {Beyond {Word} {Importance}},
	url = {https://openreview.net/forum?id=rkRwGg-0Z},
	abstract = {The driving force behind the recent success of LSTMs has been their ability to learn complex and non-linear relationships. Consequently, our inability to describe these relationships has led to...},
	urldate = {2018-10-02},
	author = {Murdoch, W. James and Liu, Peter J. and Yu, Bin},
	month = feb,
	year = {2018},
	
  booktitle={International Conference on Learning Representations},
}

@inproceedings{zeiler2014visualizing,
  title={Visualizing and understanding convolutional networks},
  author={Zeiler, Matthew D and Fergus, Rob},
  booktitle={European conference on computer vision},
  pages={818--833},
  year={2014},
  organization={Springer}
}

@article{yosinski2015understanding,
  title={Understanding neural networks through deep visualization},
  author={Yosinski, Jason and Clune, Jeff and Nguyen, Anh and Fuchs, Thomas and Lipson, Hod},
  journal={arXiv preprint arXiv:1506.06579},
  year={2015}
}


@article{rosch1999principles,
  title={Principles of categorization},
  author={Rosch, Eleanor},
  journal={Concepts: core readings},
  volume={189},
  year={1999}
}


@incollection{bos2017groningen,
  title={The Groningen meaning bank},
  author={Bos, Johan and Basile, Valerio and Evang, Kilian and Venhuizen, Noortje J and Bjerva, Johannes},
  booktitle={Handbook of linguistic annotation},
  pages={463--496},
  year={2017},
  publisher={Springer}
}


@article{frankle_lottery_2018,
	title = {The {Lottery} {Ticket} {Hypothesis}: {Training} {Pruned} {Neural} {Networks}},
	shorttitle = {The {Lottery} {Ticket} {Hypothesis}},
	url = {http://arxiv.org/abs/1803.03635},
	abstract = {Recent work on neural network pruning indicates that, at training time, neural networks need to be significantly larger in size than is necessary to represent the eventual functions that they learn. This paper articulates a new hypothesis to explain this phenomenon. This conjecture, which we term the "lottery ticket hypothesis," proposes that successful training depends on lucky random initialization of a smaller subcomponent of the network. Larger networks have more of these "lottery tickets," meaning they are more likely to luck out with a subcomponent initialized in a configuration amenable to successful optimization. This paper conducts a series of experiments with XOR and MNIST that support the lottery ticket hypothesis. In particular, we identify these fortuitously-initialized subcomponents by pruning low-magnitude weights from trained networks. We then demonstrate that these subcomponents can be successfully retrained in isolation so long as the subnetworks are given the same initializations as they had at the beginning of the training process. Initialized as such, these small networks reliably converge successfully, often faster than the original network at the same level of accuracy. However, when these subcomponents are randomly reinitialized or rearranged, they perform worse than the original network. In other words, large networks that train successfully contain small subnetworks with initializations conducive to optimization. The lottery ticket hypothesis and its connection to pruning are a step toward developing architectures, initializations, and training strategies that make it possible to solve the same problems with much smaller networks.},
	urldate = {2018-04-23},
	journal = {arXiv:1803.03635 [cs]},
	author = {Frankle, Jonathan and Carbin, Michael},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.03635},
	keywords = {Computer Science - Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1803.03635 PDF:/Users/nsaphra/Documents/zotero/storage/7LWHTA6H/Frankle and Carbin - 2018 - The Lottery Ticket Hypothesis Training Pruned Neu.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/Z7RSHWD7/1803.html:text/html}
}

@article{giulianelli_under_2018,
	title = {Under the {Hood}: {Using} {Diagnostic} {Classifiers} to {Investigate} and {Improve} how {Language} {Models} {Track} {Agreement} {Information}},
	shorttitle = {Under the {Hood}},
	url = {http://arxiv.org/abs/1808.08079},
	abstract = {How do neural language models keep track of number agreement between subject and verb? We show that `diagnostic classifiers', trained to predict number from the internal states of a language model, provide a detailed understanding of how, when, and where this information is represented. Moreover, they give us insight into when and where number information is corrupted in cases where the language model ends up making agreement errors. To demonstrate the causal role played by the representations we find, we then use agreement information to influence the course of the LSTM during the processing of difficult sentences. Results from such an intervention reveal a large increase in the language model's accuracy. Together, these results show that diagnostic classifiers give us an unrivalled detailed look into the representation of linguistic information in neural models, and demonstrate that this knowledge can be used to improve their performance.},
	urldate = {2018-08-28},
	journal = {arXiv:1808.08079 [cs]},
	author = {Giulianelli, Mario and Harding, Jack and Mohnert, Florian and Hupkes, Dieuwke and Zuidema, Willem},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.08079},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: to appear at the EMNLP workshop "Analyzing and interpreting neural networks for NLP"},
	file = {arXiv\:1808.08079 PDF:/Users/nsaphra/Documents/zotero/storage/4W566JAP/Giulianelli et al. - 2018 - Under the Hood Using Diagnostic Classifiers to In.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/L8F75GXT/1808.html:text/html}
}


@inproceedings{dhillon_two_2012,
	title = {Two {Step} {CCA}: {A} new spectral method for estimating vector models of words},
	urldate = {2014-09-16},
	booktitle = {ICML},
	author = {Dhillon, Paramveer and Rodu, Jordan and Foster, Dean and Ungar, Lyle},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6403},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language, Raman},
	annote = {Comment: Appears in Proceedings of the 29th International Conference on Machine Learning (ICML 2012)},
	file = {arXiv\:1206.6403 PDF:/Users/nsaphra/Dropbox/zotero/storage/3TUKZ558/Dhillon et al. - 2012 - Two Step CCA A new spectral method for estimating.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Dropbox/zotero/storage/UHI5UPVW/1206.html:text/html}
}

@proceedings{DBLP:conf/acl/2018-2,
  editor    = {Iryna Gurevych and
               Yusuke Miyao},
  title     = {Proceedings of the 56th Annual Meeting of the Association for Computational
               Linguistics, {ACL} 2018, Melbourne, Australia, July 15-20, 2018, Volume
               2: Short Papers},
  publisher = {Association for Computational Linguistics},
  year      = {2018},
  url       = {https://aclanthology.info/volumes/proceedings-of-the-56th-annual-meeting-of-the-association-for-computational-linguistics-volume-2-short-papers},
  isbn      = {978-1-948087-34-6},
  timestamp = {Thu, 12 Jul 2018 14:22:48 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/acl/2018-2},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{faruqui_improving_2014,
	title = {Improving vector space word representations using multilingual correlation},
	url = {http://www.aclweb.org/anthology/E14-1049},
	urldate = {2014-09-16},
	journal = {Proc. of EACL. Association for Computational Linguistics},
	author = {Faruqui, Manaal and Dyer, Chris},
	year = {2014},
	file = {[PDF] from aclweb.org:/Users/nsaphra/Dropbox/zotero/storage/3FAHWMUK/Faruqui and Dyer - 2014 - Improving vector space word representations using .pdf:application/pdf}
}

@inproceedings{dhillon_multi-view_2011,
	title = {Multi-view learning of word embeddings via cca},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2011_0157.pdf},
	urldate = {2013-12-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Dhillon, Paramveer and Foster, Dean P. and Ungar, Lyle H.},
	year = {2011},
	pages = {199--207},
	file = {[PDF] from wustl.edu:/Users/nsaphra/Dropbox/zotero/storage/DAWE6W4Q/Dhillon et al. - 2011 - Multi-view learning of word embeddings via cca.pdf:application/pdf}
}

@article{combes_learning_2018,
	title = {On the {Learning} {Dynamics} of {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1809.06848},
	abstract = {While a lot of progress has been made in recent years, the dynamics of learning in deep nonlinear neural networks remain to this day largely misunderstood. In this work, we study the case of binary classification and prove various properties of learning in such networks under strong assumptions such as linear separability of the data. Extending existing results from the linear case, we confirm empirical observations by proving that the classification error also follows a sigmoidal shape in nonlinear architectures. We show that given proper initialization, learning expounds parallel independent modes and that certain regions of parameter space might lead to failed training. We also demonstrate that input norm and features' frequency in the dataset lead to distinct convergence speeds which might shed some light on the generalization capabilities of deep neural networks. We provide a comparison between the dynamics of learning with cross-entropy and hinge losses, which could prove useful to understand recent progress in the training of generative adversarial networks. Finally, we identify a phenomenon that we baptize gradient starvation where the most frequent features in a dataset prevent the learning of other less frequent but equally informative features.},
	urldate = {2018-09-24},
	journal = {arXiv:1809.06848 [cs, stat]},
	author = {Combes, Remi Tachet des and Pezeshki, Mohammad and Shabanian, Samira and Courville, Aaron and Bengio, Yoshua},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.06848},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 19 pages, 7 figures},
	file = {arXiv\:1809.06848 PDF:/Users/nsaphra/Documents/zotero/storage/3I77E5N2/Combes et al. - 2018 - On the Learning Dynamics of Deep Neural Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/AHZEA66R/1809.html:text/html}
}


@article{feng_pathologies_2018,
	title = {Pathologies of {Neural} {Models} {Make} {Interpretations} {Difficult}},
	url = {http://arxiv.org/abs/1804.07781},
	abstract = {Model interpretability is a crucial problem in neural networks. Existing interpretation methods highlight salient input features, often determining each feature's importance based on gradient information from the model. We instead remove the least influential words, one at a time, from language inputs. This exposes pathological model behavior on language tasks: models produce high confidence values for reduced inputs, even when humans find them nonsensical. We examine the reasons for this behavior and suggest methods of mitigation. Our results have implications for gradient-based interpretation methods, showing that determining word importance using a model's gradient often does not align with humans' perceived importance of that word. We propose a simple entropy regularization technique that mitigates these issues without affecting performance on clean examples.},
	urldate = {2018-08-22},
	journal = {arXiv:1804.07781 [cs]},
	author = {Feng, Shi and Wallace, Eric and Grissom II, Alvin and Iyyer, Mohit and Rodriguez, Pedro and Boyd-Graber, Jordan},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.07781},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1804.07781 PDF:/Users/nsaphra/Documents/zotero/storage/JGNTGYWE/Feng et al. - 2018 - Pathologies of Neural Models Make Interpretations .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/JURDK758/1804.html:text/html}
}

@article{karpathy_visualizing_2015,
	title = {Visualizing and {Understanding} {Recurrent} {Networks}},
	url = {http://arxiv.org/abs/1506.02078},
	abstract = {Recurrent Neural Networks (RNNs), and specifically a variant with Long Short-Term Memory (LSTM), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while LSTMs provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing an analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, our comparative analysis with finite horizon n-gram models traces the source of the LSTM improvements to long-range structural dependencies. Finally, we provide analysis of the remaining errors and suggests areas for further study.},
	urldate = {2016-02-24},
	journal = {arXiv:1506.02078 [cs]},
	author = {Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02078},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: changing style, adding references, minor changes to text},
	file = {arXiv\:1506.02078 PDF:/Users/nsaphra/Documents/zotero/storage/QH76H6F2/Karpathy et al. - 2015 - Visualizing and Understanding Recurrent Networks.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/JCHPDFPK/1506.html:text/html}
}


@article{li_visualizing_2015,
	title = {Visualizing and understanding neural models in {NLP}},
	url = {http://arxiv.org/abs/1506.01066},
	urldate = {2016-05-26},
	journal = {arXiv preprint arXiv:1506.01066},
	author = {Li, Jiwei and Chen, Xinlei and Hovy, Eduard and Jurafsky, Dan},
	year = {2015},
	file = {[PDF] from arxiv.org:/Users/nsaphra/Documents/zotero/storage/4WVSQ5VN/Li et al. - 2015 - Visualizing and understanding neural models in NLP.pdf:application/pdf;Snapshot:/Users/nsaphra/Documents/zotero/storage/NFDTXSHZ/1506.html:text/html}
}

@inproceedings{jiaqi_mu_suma_bhat_pramod_viswanath_geometry_nodate,
	title = {{GEOMETRY} {OF} {POLYSEMY}},
	author = {{Jiaqi Mu, Suma Bhat, Pramod Viswanath}},
	file = {pdf.pdf:/Users/nsaphra/Documents/zotero/storage/MHXZC7KD/pdf.pdf:application/pdf}
}

@inproceedings{belinkov_what_2017,
	address = {Vancouver, Canada},
	title = {What do {Neural} {Machine} {Translation} {Models} {Learn} about {Morphology}?},
	url = {http://aclweb.org/anthology/P17-1080},
	abstract = {Neural machine translation (MT) models obtain state-of-the-art performance while maintaining a simple, end-to-end architecture. However, little is known about what these models learn about source and target languages during the training process. In this work, we analyze the representations learned by neural MT models at various levels of granularity and empirically evaluate the quality of the representations for learning morphology through extrinsic part-of-speech and morphological tagging tasks. We conduct a thorough investigation along several parameters: word-based vs. character-based representations, depth of the encoding layer, the identity of the target language, and encoder vs. decoder representations. Our data-driven, quantitative evaluation sheds light on important aspects in the neural MT system and its ability to capture word structure.},
	urldate = {2017-08-14},
	booktitle = {Proceedings of the 55th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Belinkov, Yonatan and Durrani, Nadir and Dalvi, Fahim and Sajjad, Hassan and Glass, James},
	month = jul,
	year = {2017},
	pages = {861--872},
	file = {Belinkov et al. - 2017 - What do Neural Machine Translation Models Learn ab.pdf:/Users/nsaphra/Documents/zotero/storage/ZXW5WJJ6/Belinkov et al. - 2017 - What do Neural Machine Translation Models Learn ab.pdf:application/pdf}
}

@article{milli_interpretable_2017,
	title = {Interpretable and {Pedagogical} {Examples}},
	url = {http://arxiv.org/abs/1711.00694},
	abstract = {Teachers intentionally pick the most informative examples to show their students. However, if the teacher and student are neural networks, the examples that the teacher network learns to give, although effective at teaching the student, are typically uninterpretable. We show that training the student and teacher iteratively, rather than jointly, can produce interpretable teaching strategies. We evaluate interpretability by (1) measuring the similarity of the teacher's emergent strategies to intuitive strategies in each domain and (2) conducting human experiments to evaluate how effective the teacher's strategies are at teaching humans. We show that the teacher network learns to select or generate interpretable, pedagogical examples to teach rule-based, probabilistic, boolean, and hierarchical concepts.},
	journal = {arXiv:1711.00694 [cs]},
	author = {Milli, Smitha and Abbeel, Pieter and Mordatch, Igor},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.00694},
	keywords = {Computer Science - Artificial Intelligence},
	file = {arXiv\:1711.00694 PDF:/Users/nsaphra/Documents/zotero/storage/JEQM7ZUT/Milli et al. - 2017 - Interpretable and Pedagogical Examples.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/BF5VNXBC/1711.html:text/html}
}

@article{andreas_analogs_2017,
	title = {Analogs of {Linguistic} {Structure} in {Deep} {Representations}},
	url = {http://arxiv.org/abs/1707.08139},
	abstract = {We investigate the compositional structure of message vectors computed by a deep network trained on a communication game. By comparing truth-conditional representations of encoder-produced message vectors to human-produced referring expressions, we are able to identify aligned (vector, utterance) pairs with the same meaning. We then search for structured relationships among these aligned pairs to discover simple vector space transformations corresponding to negation, conjunction, and disjunction. Our results suggest that neural representations are capable of spontaneously developing a "syntax" with functional analogues to qualitative properties of natural language.},
	urldate = {2018-01-19},
	journal = {arXiv:1707.08139 [cs]},
	author = {Andreas, Jacob and Klein, Dan},
	month = jul,
	year = {2017},
	note = {arXiv: 1707.08139},
	keywords = {Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: In EMNLP 2017},
	file = {arXiv\:1707.08139 PDF:/Users/nsaphra/Documents/zotero/storage/CYNBBWM4/Andreas and Klein - 2017 - Analogs of Linguistic Structure in Deep Representa.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/6X7EED4H/1707.html:text/html}
}

@article{poerner_evaluating_2018,
	title = {Evaluating neural network explanation methods using hybrid documents and morphological prediction},
	url = {http://arxiv.org/abs/1801.06422},
	abstract = {We propose two novel paradigms for evaluating neural network explanations in NLP. The first paradigm works on hybrid documents, the second exploits morphosyntactic agreements. Neither paradigm requires manual annotations; instead, a relevance ground truth is generated automatically. In our experiments, successful explanations for Long Short Term Memory networks (LSTMs) were produced by a decomposition of memory cells (Murdoch \& Szlam, 2017), while for convolutional neural networks, a gradient-based method by (Denil et al., 2014) works well. We also introduce LIMSSE, a substring-based extension of LIME (Ribeiro et al., 2016) that produces the most successful explanations in the hybrid document experiment.},
	urldate = {2018-01-22},
	journal = {arXiv:1801.06422 [cs]},
	author = {Poerner, Nina and Schütze, Hinrich and Roth, Benjamin},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.06422},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1801.06422 PDF:/Users/nsaphra/Documents/zotero/storage/H623JF3E/Poerner et al. - 2018 - Evaluating neural network explanation methods usin.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/U866YYZF/1801.html:text/html}
}

@article{sachan_investigating_2018,
	title = {Investigating the {Working} of {Text} {Classifiers}},
	url = {http://arxiv.org/abs/1801.06261},
	abstract = {Text classification is one of the most widely studied task in natural language processing. Recently, larger and larger multilayer neural network models are employed for the task motivated by the principle of compositionality. Almost all of the methods reported use discriminative approaches for the task. Discriminative approaches come with a caveat that if there is no proper capacity control, it might latch on to any signal even though it might not generalize. With use of various state-of-the-art approaches for text classifiers, we want to explore if the models actually learn to compose meaning of the sentences or still just use some key lexicons. To test our hypothesis, we construct datasets where the train and test split have no direct overlap of such lexicons. We study various text classifiers and observe that there is a big performance drop on these datasets. Finally, we show that even simple regularization techniques can improve performance on these datasets.},
	urldate = {2018-01-22},
	journal = {arXiv:1801.06261 [cs]},
	author = {Sachan, Devendra Singh and Zaheer, Manzil and Salakhutdinov, Ruslan},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.06261},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: NIPS 2017 Workshop on Deep Learning: Bridging Theory and Practice},
	file = {arXiv\:1801.06261 PDF:/Users/nsaphra/Documents/zotero/storage/JZL2XTIZ/Sachan et al. - 2018 - Investigating the Working of Text Classifiers.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/9VTN4V5H/1801.html:text/html}
}

@article{wang_comparison_2018,
	title = {A {Comparison} of {Rule} {Extraction} for {Different} {Recurrent} {Neural} {Network} {Models} and {Grammatical} {Complexity}},
	url = {http://arxiv.org/abs/1801.05420},
	abstract = {It has been shown that rules can be extracted from highly non-linear, recursive models such as recurrent neural networks (RNNs). The RNN models mostly investigated include both Elman networks and second-order recurrent networks. Recently, new types of RNNs have demonstrated superior power in handling many machine learning tasks, especially when structural data is involved such as language modeling. Here, we empirically evaluate different recurrent models on the task of learning deterministic finite automata (DFA), the seven Tomita grammars. We are interested in the capability of recurrent models with different architectures in learning and expressing regular grammars, which can be the building blocks for many applications dealing with structural data. Our experiments show that a second-order RNN provides the best and stablest performance of extracting DFA over all Tomita grammars and that other RNN models are greatly influenced by different Tomita grammars. To better understand these results, we provide a theoretical analysis of the "complexity" of different grammars, by introducing the entropy and the averaged edit distance of regular grammars defined in this paper. Through our analysis, we categorize all Tomita grammars into different classes, which explains the inconsistency in the performance of extraction observed across all RNN models.},
	urldate = {2018-01-22},
	journal = {arXiv:1801.05420 [cs]},
	author = {Wang, Qinglong and Zhang, Kaixuan and Ororbia II, Alexander G. and Xing, Xinyu and Liu, Xue and Giles, C. Lee},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.05420},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language},
	file = {arXiv\:1801.05420 PDF:/Users/nsaphra/Documents/zotero/storage/B7USCL2K/Wang et al. - 2018 - A Comparison of Rule Extraction for Different Recu.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/REJRHKB2/1801.html:text/html}
}

@article{mohseni_human-grounded_2018,
	title = {A {Human}-{Grounded} {Evaluation} {Benchmark} for {Local} {Explanations} of {Machine} {Learning}},
	url = {http://arxiv.org/abs/1801.05075},
	abstract = {In order for people to be able to trust and take advantage of the results of advanced machine learning and artificial intelligence solutions for real decision making, people need to be able to understand the machine rationale for given output. Research in explain artificial intelligence (XAI) addresses the aim, but there is a need for evaluation of human relevance and understandability of explanations. Our work contributes a novel methodology for evaluating the quality or human interpretability of explanations for machine learning models. We present an evaluation benchmark for instance explanations from text and image classifiers. The explanation meta-data in this benchmark is generated from user annotations of image and text samples. We describe the benchmark and demonstrate its utility by a quantitative evaluation on explanations generated from a recent machine learning algorithm. This research demonstrates how human-grounded evaluation could be used as a measure to qualify local machine-learning explanations.},
	urldate = {2018-01-22},
	journal = {arXiv:1801.05075 [cs]},
	author = {Mohseni, Sina and Ragan, Eric D.},
	month = jan,
	year = {2018},
	note = {arXiv: 1801.05075},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Human-Computer Interaction},
	annote = {Comment: Benchmark Available online at https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark},
	file = {arXiv\:1801.05075 PDF:/Users/nsaphra/Documents/zotero/storage/5EIJRG52/Mohseni and Ragan - 2018 - A Human-Grounded Evaluation Benchmark for Local Ex.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/44A2I6ED/1801.html:text/html}
}

@inproceedings{shi_does_2016,
	title = {Does {String}-{Based} {Neural} {MT} {Learn} {Source} {Syntax}?},
	booktitle = {{EMNLP}},
	author = {Shi, Xing and Padhi, Inkit and Knight, Kevin},
	year = {2016},
	file = {D16-1159.pdf:/Users/nsaphra/Documents/zotero/storage/ZLDSMXSR/D16-1159.pdf:application/pdf}
}

@article{gelderloos_phonemes_2016,
	title = {From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning},
	shorttitle = {From phonemes to images},
	journal = {arXiv preprint arXiv:1610.03342},
	author = {Gelderloos, Lieke and Chrupa{\textbackslash}la, Grzegorz},
	year = {2016},
	file = {Fulltext:/Users/nsaphra/Documents/zotero/storage/MD8GUF2P/Gelderloos and Chrupala - 2016 - From phonemes to images levels of representation .pdf:application/pdf;Snapshot:/Users/nsaphra/Documents/zotero/storage/KSD9LKC9/1610.html:text/html}
}

@misc{noauthor_[1801.09808]_nodate,
	title = {[1801.09808] {The} {Intriguing} {Properties} of {Model} {Explanations}},
	url = {https://arxiv.org/abs/1801.09808},
	urldate = {2018-02-04},
	file = {[1801.09808] The Intriguing Properties of Model Explanations:/Users/nsaphra/Documents/zotero/storage/N4JFXMMT/1801.html:text/html}
}

@article{williams_learning_2017,
	title = {Learning to parse from a semantic objective: {It} works. {Is} it syntax?},
	shorttitle = {Learning to parse from a semantic objective},
	url = {http://arxiv.org/abs/1709.01121},
	abstract = {Recent work on reinforcement learning and other gradient estimators for latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting parse to interpret the sentence, all without exposure to ground-truth parse trees at training time. Surprisingly, these models often perform better at sentence understanding tasks than models that use parse trees from conventional parsers. This paper aims to investigate what these latent tree learning models learn. We replicate two such models in a shared codebase and find that (i) they do outperform baselines on sentence classification, but that (ii) their parsing strategies are not especially consistent across random restarts, (iii) the parses they produce tend to be shallower than PTB parses, and (iv) these do not resemble those of PTB or of any other recognizable semantic or syntactic grammar formalism.},
	urldate = {2018-02-04},
	journal = {arXiv:1709.01121 [cs]},
	author = {Williams, Adina and Drozdov, Andrew and Bowman, Samuel R.},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.01121},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 13 pages, 6 figures, 4 tables, submitted to TACL},
	file = {arXiv\:1709.01121 PDF:/Users/nsaphra/Documents/zotero/storage/SL5D3TWX/Williams et al. - 2017 - Learning to parse from a semantic objective It wo.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/EFEXFTBB/1709.html:text/html}
}

@article{belinkov_evaluating_2018,
	title = {Evaluating {Layers} of {Representation} in {Neural} {Machine} {Translation} on {Part}-of-{Speech} and {Semantic} {Tagging} {Tasks}},
	volume = {abs/1801.07772},
	url = {http://arxiv.org/abs/1801.07772},
	journal = {CoRR},
	author = {Belinkov, Yonatan and Màrquez, Lluís and Sajjad, Hassan and Durrani, Nadir and Dalvi, Fahim and Glass, James R.},
	year = {2018},
	file = {arXiv\:1801.07772 PDF:/Users/nsaphra/Documents/zotero/storage/36Q5FS25/Belinkov et al. - 2018 - Evaluating Layers of Representation in Neural Mach.pdf:application/pdf}
}

@inproceedings{smith_what_2017,
	title = {What {Do} {Recurrent} {Neural} {Network} {Grammars} {Learn} {About} {Syntax}?},
	booktitle = {{EACL}},
	author = {Smith, Noah A. and Dyer, Chris and Ballesteros, Miguel and Neubig, Graham and Kong, Lingpeng and Kuncoro, Adhiguna},
	year = {2017},
	file = {d85224031ec6c970ad5603f0dc96cc83ae4d.pdf:/Users/nsaphra/Documents/zotero/storage/IATZ6XZV/d85224031ec6c970ad5603f0dc96cc83ae4d.pdf:application/pdf}
}

@inproceedings{bowman_tree-structured_2015,
	title = {Tree-structured composition in neural networks without tree-structured architectures},
	url = {http://arxiv.org/abs/1506.04834},
	abstract = {Tree-structured neural networks encode a particular tree geometry for a sentence in the network design. However, these models have at best only slightly outperformed simpler sequence-based models. We hypothesize that neural sequence models like LSTMs are in fact able to discover and implicitly use recursive compositional structure, at least for tasks with clear cues to that structure in the data. We demonstrate this possibility using an artificial data task for which recursive compositional structure is crucial, and find an LSTM-based sequence model can indeed learn to exploit the underlying tree structure. However, its performance consistently lags behind that of tree models, even on large training sets, suggesting that tree-structured models are more effective at exploiting recursive structure.},
	urldate = {2018-02-17},
	booktitle = {{arXiv}:1506.04834 [cs]},
	author = {Bowman, Samuel R. and Manning, Christopher D. and Potts, Christopher},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.04834},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language},
	annote = {Comment: To appear in the proceedings of the 2015 NIPS Workshop on Cognitive Computation: Integrating Neural and Symbolic Approaches},
	file = {arXiv\:1506.04834 PDF:/Users/nsaphra/Documents/zotero/storage/YRIXCENN/Bowman et al. - 2015 - Tree-structured composition in neural networks wit.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/9PQ9JZCQ/1506.html:text/html}
}

@article{wu_beyond_2017,
	title = {Beyond {Sparsity}: {Tree} {Regularization} of {Deep} {Models} for {Interpretability}},
	shorttitle = {Beyond {Sparsity}},
	url = {http://arxiv.org/abs/1711.06178},
	abstract = {The lack of interpretability remains a key barrier to the adoption of deep models in many applications. In this work, we explicitly regularize deep models so human users might step through the process behind their predictions in little time. Specifically, we train deep time-series models so their class-probability predictions have high accuracy while being closely modeled by decision trees with few nodes. Using intuitive toy examples as well as medical tasks for treating sepsis and HIV, we demonstrate that this new tree regularization yields models that are easier for humans to simulate than simpler L1 or L2 penalties without sacrificing predictive power.},
	urldate = {2018-02-26},
	journal = {arXiv:1711.06178 [cs, stat]},
	author = {Wu, Mike and Hughes, Michael C. and Parbhoo, Sonali and Zazzi, Maurizio and Roth, Volker and Doshi-Velez, Finale},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.06178},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: To appear in AAAI 2018. Contains 9-page main paper and appendix with supplementary material},
	file = {arXiv\:1711.06178 PDF:/Users/nsaphra/Documents/zotero/storage/JJXGLDV4/Wu et al. - 2017 - Beyond Sparsity Tree Regularization of Deep Model.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/V8NA7IQT/1711.html:text/html}
}

@article{neto_detecting_2018,
	title = {Detecting {Learning} vs {Memorization} in {Deep} {Neural} {Networks} using {Shared} {Structure} {Validation} {Sets}},
	url = {http://arxiv.org/abs/1802.07714},
	abstract = {The roles played by learning and memorization represent an important topic in deep learning research. Recent work on this subject has shown that the optimization behavior of DNNs trained on shuffled labels is qualitatively different from DNNs trained with real labels. Here, we propose a novel permutation approach that can differentiate memorization from learning in deep neural networks (DNNs) trained as usual (i.e., using the real labels to guide the learning, rather than shuffled labels). The evaluation of weather the DNN has learned and/or memorized, happens in a separate step where we compare the predictive performance of a shallow classifier trained with the features learned by the DNN, against multiple instances of the same classifier, trained on the same input, but using shuffled labels as outputs. By evaluating these shallow classifiers in validation sets that share structure with the training set, we are able to tell apart learning from memorization. Application of our permutation approach to multi-layer perceptrons and convolutional neural networks trained on image data corroborated many findings from other groups. Most importantly, our illustrations also uncovered interesting dynamic patterns about how DNNs memorize over increasing numbers of training epochs, and support the surprising result that DNNs are still able to learn, rather than only memorize, when trained with pure Gaussian noise as input.},
	urldate = {2018-02-26},
	journal = {arXiv:1802.07714 [cs, stat]},
	author = {Neto, Elias Chaibub},
	month = feb,
	year = {2018},
	note = {arXiv: 1802.07714},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	file = {arXiv\:1802.07714 PDF:/Users/nsaphra/Documents/zotero/storage/LUNGDW9Z/Neto - 2018 - Detecting Learning vs Memorization in Deep Neural .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/38XPKLXT/1802.html:text/html}
}

@article{ross_improving_2017,
	title = {Improving the {Adversarial} {Robustness} and {Interpretability} of {Deep} {Neural} {Networks} by {Regularizing} their {Input} {Gradients}},
	url = {http://arxiv.org/abs/1711.09404},
	abstract = {Deep neural networks have proven remarkably effective at solving many classification problems, but have been criticized recently for two major weaknesses: the reasons behind their predictions are uninterpretable, and the predictions themselves can often be fooled by small adversarial perturbations. These problems pose major obstacles for the adoption of neural networks in domains that require security or transparency. In this work, we evaluate the effectiveness of defenses that differentiably penalize the degree to which small changes in inputs can alter model predictions. Across multiple attacks, architectures, defenses, and datasets, we find that neural networks trained with this input gradient regularization exhibit robustness to transferred adversarial examples generated to fool all of the other models. We also find that adversarial examples generated to fool gradient-regularized models fool all other models equally well, and actually lead to more "legitimate," interpretable misclassifications as rated by people (which we confirm in a human subject experiment). Finally, we demonstrate that regularizing input gradients makes them more naturally interpretable as rationales for model predictions. We conclude by discussing this relationship between interpretability and robustness in deep neural networks.},
	urldate = {2018-02-26},
	journal = {arXiv:1711.09404 [cs]},
	author = {Ross, Andrew Slavin and Doshi-Velez, Finale},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.09404},
	keywords = {Computer Science - Learning, Computer Science - Cryptography and Security, Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: To appear in AAAI 2018},
	file = {arXiv\:1711.09404 PDF:/Users/nsaphra/Documents/zotero/storage/AUSDAZCW/Ross and Doshi-Velez - 2017 - Improving the Adversarial Robustness and Interpret.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/S8U9M3EC/1711.html:text/html}
}

@misc{noauthor_interpretable_2018,
	title = {Interpretable {Machine} {Learning} through {Teaching}},
	url = {https://blog.openai.com/interpretable-machine-learning-through-teaching/},
	abstract = {We've designed a method that encourages AIs to teach each other with examples that also make sense to humans. Our approach automatically selects the most informative examples to teach a concept — for instance, the best images to describe the concept of dogs — and experimentally we found our approach to be},
	urldate = {2018-02-26},
	journal = {OpenAI Blog},
	month = feb,
	year = {2018},
	file = {Snapshot:/Users/nsaphra/Documents/zotero/storage/LKBV56GI/interpretable-machine-learning-through-teaching.html:text/html}
}

@article{morcos_importance_2018,
	title = {On the importance of single directions for generalization},
	url = {http://arxiv.org/abs/1803.06959},
	abstract = {Despite their ability to memorize large datasets, deep neural networks often achieve good generalization performance. However, the differences between the learned solutions of networks which generalize and those which do not remain unclear. Additionally, the tuning properties of single directions (defined as the activation of a single unit or some linear combination of units in response to some input) have been highlighted, but their importance has not been evaluated. Here, we connect these lines of inquiry to demonstrate that a network's reliance on single directions is a good predictor of its generalization performance, across networks trained on datasets with different fractions of corrupted labels, across ensembles of networks trained on datasets with unmodified labels, across different hyperparameters, and over the course of training. While dropout only regularizes this quantity up to a point, batch normalization implicitly discourages single direction reliance, in part by decreasing the class selectivity of individual units. Finally, we find that class selectivity is a poor predictor of task importance, suggesting not only that networks which generalize well minimize their dependence on individual units by reducing their selectivity, but also that individually selective units may not be necessary for strong network performance.},
	urldate = {2018-05-04},
	journal = {arXiv:1803.06959 [cs, stat]},
	author = {Morcos, Ari S. and Barrett, David G. T. and Rabinowitz, Neil C. and Botvinick, Matthew},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.06959},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: ICLR 2018 conference paper},
	file = {arXiv\:1803.06959 PDF:/Users/nsaphra/Documents/zotero/storage/9GVGPFYT/Morcos et al. - 2018 - On the importance of single directions for general.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/UNZLTQGD/1803.html:text/html}
}

@article{conneau_what_2018,
	title = {What you can cram into a single vector: {Probing} sentence embeddings for linguistic properties},
	shorttitle = {What you can cram into a single vector},
	url = {http://arxiv.org/abs/1805.01070},
	abstract = {Although much effort has recently been devoted to training high-quality sentence embeddings, we still have a poor understanding of what they are capturing. "Downstream" tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The complexity of the tasks makes it however difficult to infer what kind of information is present in the representations. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different encoders trained in eight distinct ways, uncovering intriguing properties of both encoders and training methods.},
	urldate = {2018-05-08},
	journal = {arXiv:1805.01070 [cs]},
	author = {Conneau, Alexis and Kruszewski, German and Lample, Guillaume and Barrault, Loïc and Baroni, Marco},
	month = may,
	year = {2018},
	note = {arXiv: 1805.01070},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: ACL 2018},
	file = {arXiv\:1805.01070 PDF:/Users/nsaphra/Documents/zotero/storage/UTPDFSNM/Conneau et al. - 2018 - What you can cram into a single vector Probing se.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/G95FGKTY/1805.html:text/html}
}

@article{linzen_assessing_2016,
	title = {Assessing the {Ability} of {LSTMs} to {Learn} {Syntax}-{Sensitive} {Dependencies}},
	url = {http://arxiv.org/abs/1611.01368},
	abstract = {The success of long short-term memory (LSTM) neural networks in language processing is typically attributed to their ability to capture long-distance statistical regularities. Linguistic regularities are often sensitive to syntactic structure; can such dependencies be captured by LSTMs, which do not have explicit structural representations? We begin addressing this question using number agreement in English subject-verb dependencies. We probe the architecture's grammatical competence both using training objectives with an explicit grammatical target (number prediction, grammaticality judgments) and using language models. In the strongly supervised settings, the LSTM achieved very high overall accuracy (less than 1\% errors), but errors increased when sequential and structural information conflicted. The frequency of such errors rose sharply in the language-modeling setting. We conclude that LSTMs can capture a non-trivial amount of grammatical structure given targeted supervision, but stronger architectures may be required to further reduce errors; furthermore, the language modeling signal is insufficient for capturing syntax-sensitive dependencies, and should be supplemented with more direct supervision if such dependencies need to be captured.},
	urldate = {2018-05-10},
	journal = {arXiv:1611.01368 [cs]},
	author = {Linzen, Tal and Dupoux, Emmanuel and Goldberg, Yoav},
	month = nov,
	year = {2016},
	note = {arXiv: 1611.01368},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 15 pages; to appear in Transactions of the Association for Computational Linguistics},
	file = {arXiv\:1611.01368 PDF:/Users/nsaphra/Documents/zotero/storage/LECGDNLS/Linzen et al. - 2016 - Assessing the Ability of LSTMs to Learn Syntax-Sen.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/VIYN5YEI/1611.html:text/html}
}

@article{gulordava_colorless_2018,
	title = {Colorless green recurrent networks dream hierarchically},
	url = {http://arxiv.org/abs/1803.11138},
	abstract = {Recurrent neural networks (RNNs) have achieved impressive results in a variety of linguistic processing tasks, suggesting that they can induce non-trivial properties of language. We investigate here to what extent RNNs learn to track abstract hierarchical syntactic structure. We test whether RNNs trained with a generic language modeling objective in four languages (Italian, English, Hebrew, Russian) can predict long-distance number agreement in various constructions. We include in our evaluation nonsensical sentences where RNNs cannot rely on semantic or lexical cues ("The colorless green ideas I ate with the chair sleep furiously"), and, for Italian, we compare model performance to human intuitions. Our language-model-trained RNNs make reliable predictions about long-distance agreement, and do not lag much behind human performance. We thus bring support to the hypothesis that RNNs are not just shallow-pattern extractors, but they also acquire deeper grammatical competence.},
	urldate = {2018-05-10},
	journal = {arXiv:1803.11138 [cs]},
	author = {Gulordava, Kristina and Bojanowski, Piotr and Grave, Edouard and Linzen, Tal and Baroni, Marco},
	month = mar,
	year = {2018},
	note = {arXiv: 1803.11138},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to NAACL 2018},
	file = {arXiv\:1803.11138 PDF:/Users/nsaphra/Documents/zotero/storage/RRX7F4S4/Gulordava et al. - 2018 - Colorless green recurrent networks dream hierarchi.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/AV3KVBLF/1803.html:text/html}
}

@article{radford_learning_2017,
	title = {Learning to {Generate} {Reviews} and {Discovering} {Sentiment}},
	url = {http://arxiv.org/abs/1704.01444},
	abstract = {We explore the properties of byte-level recurrent language models. When given sufficient amounts of capacity, training data, and compute time, the representations learned by these models include disentangled features corresponding to high-level concepts. Specifically, we find a single unit which performs sentiment analysis. These representations, learned in an unsupervised manner, achieve state of the art on the binary subset of the Stanford Sentiment Treebank. They are also very data efficient. When using only a handful of labeled examples, our approach matches the performance of strong baselines trained on full datasets. We also demonstrate the sentiment unit has a direct influence on the generative process of the model. Simply fixing its value to be positive or negative generates samples with the corresponding positive or negative sentiment.},
	urldate = {2018-05-14},
	journal = {arXiv:1704.01444 [cs]},
	author = {Radford, Alec and Jozefowicz, Rafal and Sutskever, Ilya},
	month = apr,
	year = {2017},
	note = {arXiv: 1704.01444},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv\:1704.01444 PDF:/Users/nsaphra/Documents/zotero/storage/M9QWVQT2/Radford et al. - 2017 - Learning to Generate Reviews and Discovering Senti.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/VDGBG6UT/1704.html:text/html}
}

@article{camacho-collados_word_2018,
	title = {From {Word} to {Sense} {Embeddings}: {A} {Survey} on {Vector} {Representations} of {Meaning}},
	shorttitle = {From {Word} to {Sense} {Embeddings}},
	url = {http://arxiv.org/abs/1805.04032},
	abstract = {Over the past years, distributed representations have proven effective and flexible keepers of prior knowledge to be integrated into downstream applications. This survey is focused on semantic representation of meaning. We start from the theoretical background behind word vector space models and highlight one of their main limitations: the meaning conflation deficiency, which arises from representing a word with all its possible meanings as a single vector. Then, we explain how this deficiency can be addressed through a transition from word level to the more fine-grained level of word senses (in its broader acceptation) as a method for modelling unambiguous lexical meaning. We present a comprehensive overview of the wide range of techniques in the two main branches of sense representation, i.e., unsupervised and knowledge-based. Finally, this survey covers the main evaluation procedures and provides an analysis of five important aspects: interpretability, sense granularity, adaptability to different domains, compositionality and integration into downstream applications.},
	urldate = {2018-05-15},
	journal = {arXiv:1805.04032 [cs]},
	author = {Camacho-Collados, Jose and Pilehvar, Mohammad Taher},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04032},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: 40 pages, 8 figures. Submitted to JAIR},
	file = {arXiv\:1805.04032 PDF:/Users/nsaphra/Documents/zotero/storage/DFQ772BD/Camacho-Collados and Pilehvar - 2018 - From Word to Sense Embeddings A Survey on Vector .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/M8HN37BY/1805.html:text/html}
}

@article{hupkes_visualisation_2017,
	title = {Visualisation and 'diagnostic classifiers' reveal how recurrent and recursive neural networks process hierarchical structure},
	url = {http://arxiv.org/abs/1711.10203},
	abstract = {We investigate how neural networks can learn and process languages with hierarchical, compositional semantics. To this end, we define the artificial task of processing nested arithmetic expressions, and study whether different types of neural networks can learn to compute their meaning. We find that recursive neural networks can find a generalising solution to this problem, and we visualise this solution by breaking it up in three steps: project, sum and squash. As a next step, we investigate recurrent neural networks, and show that a gated recurrent unit, that processes its input incrementally, also performs very well on this task. To develop an understanding of what the recurrent network encodes, visualisation techniques alone do not suffice. Therefore, we develop an approach where we formulate and test multiple hypotheses on the information encoded and processed by the network. For each hypothesis, we derive predictions about features of the hidden state representations at each time step, and train 'diagnostic classifiers' to test those predictions. Our results indicate that the networks follow a strategy similar to our hypothesised 'cumulative strategy', which explains the high accuracy of the network on novel expressions, the generalisation to longer expressions than seen in training, and the mild deterioration with increasing length. This is turn shows that diagnostic classifiers can be a useful technique for opening up the black box of neural networks. We argue that diagnostic classification, unlike most visualisation techniques, does scale up from small networks in a toy domain, to larger and deeper recurrent networks dealing with real-life data, and may therefore contribute to a better understanding of the internal dynamics of current state-of-the-art models in natural language processing.},
	urldate = {2018-05-15},
	journal = {arXiv:1711.10203 [cs]},
	author = {Hupkes, Dieuwke and Veldhoen, Sara and Zuidema, Willem},
	month = nov,
	year = {2017},
	note = {arXiv: 1711.10203},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 20 pages},
	file = {arXiv\:1711.10203 PDF:/Users/nsaphra/Documents/zotero/storage/FXTDA5PZ/Hupkes et al. - 2017 - Visualisation and 'diagnostic classifiers' reveal .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/N28ET9GS/1711.html:text/html}
}

@article{blevins_deep_2018,
	title = {Deep {RNNs} {Encode} {Soft} {Hierarchical} {Syntax}},
	url = {http://arxiv.org/abs/1805.04218},
	abstract = {We present a set of experiments to demonstrate that deep recurrent neural networks (RNNs) learn internal representations that capture soft hierarchical notions of syntax from highly varied supervision. We consider four syntax tasks at different depths of the parse tree; for each word, we predict its part of speech as well as the first (parent), second (grandparent) and third level (great-grandparent) constituent labels that appear above it. These predictions are made from representations produced at different depths in networks that are pretrained with one of four objectives: dependency parsing, semantic role labeling, machine translation, or language modeling. In every case, we find a correspondence between network depth and syntactic depth, suggesting that a soft syntactic hierarchy emerges. This effect is robust across all conditions, indicating that the models encode significant amounts of syntax even in the absence of an explicit syntactic training supervision.},
	urldate = {2018-05-16},
	journal = {arXiv:1805.04218 [cs]},
	author = {Blevins, Terra and Levy, Omer and Zettlemoyer, Luke},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04218},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: Accepted to ACL 2018},
	file = {arXiv\:1805.04218 PDF:/Users/nsaphra/Documents/zotero/storage/A25YXQMA/Blevins et al. - 2018 - Deep RNNs Encode Soft Hierarchical Syntax.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/R2ACQEM6/1805.html:text/html}
}

@article{khandelwal_sharp_2018,
	title = {Sharp {Nearby}, {Fuzzy} {Far} {Away}: {How} {Neural} {Language} {Models} {Use} {Context}},
	shorttitle = {Sharp {Nearby}, {Fuzzy} {Far} {Away}},
	url = {http://arxiv.org/abs/1805.04623},
	abstract = {We know very little about how neural language models (LM) use prior linguistic context. In this paper, we investigate the role of context in an LSTM LM, through ablation studies. Specifically, we analyze the increase in perplexity when prior context words are shuffled, replaced, or dropped. On two standard datasets, Penn Treebank and WikiText-2, we find that the model is capable of using about 200 tokens of context on average, but sharply distinguishes nearby context (recent 50 tokens) from the distant history. The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic. We further find that the neural caching model (Grave et al., 2017b) especially helps the LSTM to copy words from within this distant context. Overall, our analysis not only provides a better understanding of how neural LMs use their context, but also sheds light on recent success from cache-based models.},
	urldate = {2018-06-04},
	journal = {arXiv:1805.04623 [cs]},
	author = {Khandelwal, Urvashi and He, He and Qi, Peng and Jurafsky, Dan},
	month = may,
	year = {2018},
	note = {arXiv: 1805.04623},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: ACL 2018},
	file = {arXiv\:1805.04623 PDF:/Users/nsaphra/Documents/zotero/storage/PQP727LG/Khandelwal et al. - 2018 - Sharp Nearby, Fuzzy Far Away How Neural Language .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/3UE6QJCD/1805.html:text/html}
}

@article{gaddy_whats_2018,
	title = {What's {Going} {On} in {Neural} {Constituency} {Parsers}? {An} {Analysis}},
	shorttitle = {What's {Going} {On} in {Neural} {Constituency} {Parsers}?},
	url = {http://arxiv.org/abs/1804.07853},
	abstract = {A number of differences have emerged between modern and classic approaches to constituency parsing in recent years, with structural components like grammars and feature-rich lexicons becoming less central while recurrent neural network representations rise in popularity. The goal of this work is to analyze the extent to which information provided directly by the model structure in classical systems is still being captured by neural methods. To this end, we propose a high-performance neural model (92.08 F1 on PTB) that is representative of recent work and perform a series of investigative experiments. We find that our model implicitly learns to encode much of the same information that was explicitly provided by grammars and lexicons in the past, indicating that this scaffolding can largely be subsumed by powerful general-purpose neural machinery.},
	urldate = {2018-06-04},
	journal = {arXiv:1804.07853 [cs]},
	author = {Gaddy, David and Stern, Mitchell and Klein, Dan},
	month = apr,
	year = {2018},
	note = {arXiv: 1804.07853},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: NAACL 2018},
	file = {arXiv\:1804.07853 PDF:/Users/nsaphra/Documents/zotero/storage/8IN4ABMF/Gaddy et al. - 2018 - What's Going On in Neural Constituency Parsers An.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/EHD6NA52/1804.html:text/html}
}

@article{levy_long_2018,
	title = {Long {Short}-{Term} {Memory} as a {Dynamically} {Computed} {Element}-wise {Weighted} {Sum}},
	url = {http://arxiv.org/abs/1805.03716},
	abstract = {LSTMs were introduced to combat vanishing gradients in simple RNNs by augmenting them with gated additive recurrent connections. We present an alternative view to explain the success of LSTMs: the gates themselves are versatile recurrent models that provide more representational power than previously appreciated. We do this by decoupling the LSTM's gates from the embedded simple RNN, producing a new class of RNNs where the recurrence computes an element-wise weighted sum of context-independent functions of the input. Ablations on a range of problems demonstrate that the gating mechanism alone performs as well as an LSTM in most settings, strongly suggesting that the gates are doing much more in practice than just alleviating vanishing gradients.},
	urldate = {2018-06-04},
	journal = {arXiv:1805.03716 [cs, stat]},
	author = {Levy, Omer and Lee, Kenton and FitzGerald, Nicholas and Zettlemoyer, Luke},
	month = may,
	year = {2018},
	note = {arXiv: 1805.03716},
	keywords = {Computer Science - Learning, Statistics - Machine Learning, Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	annote = {Comment: ACL 2018},
	file = {arXiv\:1805.03716 PDF:/Users/nsaphra/Documents/zotero/storage/YQIFKV79/Levy et al. - 2018 - Long Short-Term Memory as a Dynamically Computed E.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/PF422XT4/1805.html:text/html}
}

@article{liu_lstms_2018,
	title = {{LSTMs} {Exploit} {Linguistic} {Attributes} of {Data}},
	url = {http://arxiv.org/abs/1805.11653},
	abstract = {While recurrent neural networks have found success in a variety of natural language processing applications, they are general models of sequential data. We investigate how the properties of natural language data affect an LSTM's ability to learn a nonlinguistic task: recalling elements from its input. We find that models trained on natural language data are able to recall tokens from much longer sequences than models trained on non-language sequential data. Furthermore, we show that the LSTM learns to solve the memorization task by explicitly using a subset of its neurons to count timesteps in the input. We hypothesize that the patterns and structure in natural language data enable LSTMs to learn by providing approximate ways of reducing loss, but understanding the effect of different training data on the learnability of LSTMs remains an open question.},
	urldate = {2018-06-04},
	journal = {arXiv:1805.11653 [cs]},
	author = {Liu, Nelson F. and Levy, Omer and Schwartz, Roy and Tan, Chenhao and Smith, Noah A.},
	month = may,
	year = {2018},
	note = {arXiv: 1805.11653},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 7 pages, 4 figures; accepted to ACL 2018 RepL4NLP workshop},
	file = {arXiv\:1805.11653 PDF:/Users/nsaphra/Documents/zotero/storage/ZTVHYIGR/Liu et al. - 2018 - LSTMs Exploit Linguistic Attributes of Data.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/9ZUVCX5E/1805.html:text/html}
}

@article{raghu_svcca:_2017,
	title = {{SVCCA}: {Singular} {Vector} {Canonical} {Correlation} {Analysis} for {Deep} {Learning} {Dynamics} and {Interpretability}},
	shorttitle = {{SVCCA}},
	url = {http://arxiv.org/abs/1706.05806},
	abstract = {We propose a new technique, Singular Vector Canonical Correlation Analysis (SVCCA), a tool for quickly comparing two representations in a way that is both invariant to affine transform (allowing comparison between different layers and networks) and fast to compute (allowing more comparisons to be calculated than with previous methods). We deploy this tool to measure the intrinsic dimensionality of layers, showing in some cases needless over-parameterization; to probe learning dynamics throughout training, finding that networks converge to final representations from the bottom up; to show where class-specific information in networks is formed; and to suggest new training regimes that simultaneously save computation and overfit less. Code: https://github.com/google/svcca/},
	urldate = {2018-06-08},
	journal = {arXiv:1706.05806 [cs, stat]},
	author = {Raghu, Maithra and Gilmer, Justin and Yosinski, Jason and Sohl-Dickstein, Jascha},
	month = jun,
	year = {2017},
	note = {arXiv: 1706.05806},
	keywords = {Computer Science - Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted to NIPS 2017, code: https://github.com/google/svcca/ , new plots on Imagenet},
	file = {arXiv\:1706.05806 PDF:/Users/nsaphra/Documents/zotero/storage/7SB3M4QX/Raghu et al. - 2017 - SVCCA Singular Vector Canonical Correlation Analy.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/SXV6WADP/1706.html:text/html}
}

@article{li_convergent_2015,
	title = {Convergent {Learning}: {Do} different neural networks learn the same representations?},
	shorttitle = {Convergent {Learning}},
	url = {http://arxiv.org/abs/1511.07543},
	abstract = {Recent success in training deep neural networks have prompted active investigation into the features learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of parameters, but valuable because it increases our ability to understand current models and create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar low-dimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question using three techniques to approximately align different neural networks on a feature level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes show evidence of being a mix between a local code and slightly, but not fully, distributed codes across multiple units.},
	urldate = {2018-06-11},
	journal = {arXiv:1511.07543 [cs]},
	author = {Li, Yixuan and Yosinski, Jason and Clune, Jeff and Lipson, Hod and Hopcroft, John},
	month = nov,
	year = {2015},
	note = {arXiv: 1511.07543},
	keywords = {Computer Science - Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: Published as a conference paper at ICLR 2016},
	file = {arXiv\:1511.07543 PDF:/Users/nsaphra/Documents/zotero/storage/H5C9BTQQ/Li et al. - 2015 - Convergent Learning Do different neural networks .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/DKSVMJGD/1511.html:text/html}
}

@article{adi_fine-grained_2016,
	title = {Fine-grained {Analysis} of {Sentence} {Embeddings} {Using} {Auxiliary} {Prediction} {Tasks}},
	url = {http://arxiv.org/abs/1608.04207},
	abstract = {There is a lot of research interest in encoding variable length sentences into fixed length vectors, in a way that preserves the sentence meanings. Two common methods include representations based on averaging word vectors, and representations based on the hidden states of recurrent neural networks such as LSTMs. The sentence vectors are used as features for subsequent machine learning tasks or for pre-training in the context of deep learning. However, not much is known about the properties that are encoded in these sentence representations and about the language information they capture. We propose a framework that facilitates better understanding of the encoded representations. We define prediction tasks around isolated aspects of sentence structure (namely sentence length, word content, and word order), and score representations by the ability to train a classifier to solve each prediction task when using the representation as input. We demonstrate the potential contribution of the approach by analyzing different sentence representation mechanisms. The analysis sheds light on the relative strengths of different sentence embedding methods with respect to these low level prediction tasks, and on the effect of the encoded vector's dimensionality on the resulting representations.},
	urldate = {2018-06-12},
	journal = {arXiv:1608.04207 [cs]},
	author = {Adi, Yossi and Kermany, Einat and Belinkov, Yonatan and Lavi, Ofer and Goldberg, Yoav},
	month = aug,
	year = {2016},
	note = {arXiv: 1608.04207},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv\:1608.04207 PDF:/Users/nsaphra/Documents/zotero/storage/3Y63FBS5/Adi et al. - 2016 - Fine-grained Analysis of Sentence Embeddings Using.pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/QWEBHL57/1608.html:text/html}
}


@article{shwartz-ziv_opening_2017,
	title = {Opening the {Black} {Box} of {Deep} {Neural} {Networks} via {Information}},
	url = {http://arxiv.org/abs/1703.00810},
	abstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work proposed to analyze DNNs in the {\textbackslash}textit\{Information Plane\}; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compression and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on \{{\textbackslash}emph compression\} of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer.},
	urldate = {2018-05-14},
	journal = {arXiv:1703.00810 [cs]},
	author = {Shwartz-Ziv, Ravid and Tishby, Naftali},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.00810},
	keywords = {Computer Science - Learning},
	annote = {Comment: 19 pages, 8 figures},
	annote = {during training, networks proceed first through a loss minimization phase followed by a compression phase},
	file = {arXiv\:1703.00810 PDF:/Users/nsaphra/Documents/zotero/storage/A7PPD9ZM/Shwartz-Ziv and Tishby - 2017 - Opening the Black Box of Deep Neural Networks via .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/F7CF7WSS/1703.html:text/html}
}


@inproceedings{bjerva_semantic_2016,
	title = {Semantic {Tagging} with {Deep} {Residual} {Networks}},
	booktitle = {{COLING}},
	author = {Bjerva, Johannes and Plank, Barbara and Bos, Johan},
	year = {2016},
	file = {f1b0b89febce08d44ddefe6d8be6378afbf0.pdf:/Users/nsaphra/Documents/zotero/storage/BP5K9DVF/f1b0b89febce08d44ddefe6d8be6378afbf0.pdf:application/pdf}
}

@article{zhang2016understanding,
  title={Understanding deep learning requires rethinking generalization},
  author={Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1611.03530},
  year={2016}
}


@article{morcos_insights_2018,
	title = {Insights on representational similarity in neural networks with canonical correlation},
	url = {http://arxiv.org/abs/1806.05759},
	abstract = {Comparing different neural network representations and determining how representations evolve over time remain challenging open questions in our understanding of the function of neural networks. Comparing representations in neural networks is fundamentally difficult as the structure of representations varies greatly, even across groups of networks trained on identical tasks, and over the course of training. Here, we develop projection weighted CCA (Canonical Correlation Analysis) as a tool for understanding neural networks, building off of SVCCA, a recently proposed method. We first improve the core method, showing how to differentiate between signal and noise, and then apply this technique to compare across a group of CNNs, demonstrating that networks which generalize converge to more similar representations than networks which memorize, that wider networks converge to more similar solutions than narrow networks, and that trained networks with identical topology but different learning rates converge to distinct clusters with diverse representations. We also investigate the representational dynamics of RNNs, across both training and sequential timesteps, finding that RNNs converge in a bottom-up pattern over the course of training and that the hidden state is highly variable over the course of a sequence, even when accounting for linear transforms. Together, these results provide new insights into the function of CNNs and RNNs, and demonstrate the utility of using CCA to understand representations.},
	urldate = {2018-06-20},
	journal = {arXiv:1806.05759 [cs, stat]},
	author = {Morcos, Ari S. and Raghu, Maithra and Bengio, Samy},
	month = jun,
	year = {2018},
	note = {arXiv: 1806.05759},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
	annote = {Comment: NIPS 2018 submission},
	file = {arXiv\:1806.05759 PDF:/Users/nsaphra/Documents/zotero/storage/8PXVDL4X/Morcos et al. - 2018 - Insights on representational similarity in neural .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/BYBQPAGN/1806.html:text/html}
}


@inproceedings{mikolov_distributed_2013,
	title = {Distributed {Representations} of {Words} and {Phrases} and their {Compositionality}},
	url = {http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf},
	urldate = {2014-04-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 26},
	publisher = {Curran Associates, Inc.},
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	editor = {Burges, C. J. C. and Bottou, L. and Welling, M. and Ghahramani, Z. and Weinberger, K. Q.},
	year = {2013},
	keywords = {Raman},
	pages = {3111--3119},
	file = {NIPS Full Text PDF:/Users/nsaphra/Documents/zotero/storage/UDQ3QJIX/Mikolov et al. - 2013 - Distributed Representations of Words and Phrases a.pdf:application/pdf;NIPS Snapshort:/Users/nsaphra/Documents/zotero/storage/ME37VZAR/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.html:text/html}
}

@inproceedings{alishahi2017encoding,
  title={Encoding of phonology in a recurrent neural model of grounded speech},
  author={Alishahi, Afra and Barking, Marie and Chrupa{\l}a, Grzegorz},
  booktitle={Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)},
  pages={368--378},
  year={2017}
}

@article{kadar_representation_2016,
	title = {Representation of linguistic form and function in recurrent neural networks},
	url = {http://arxiv.org/abs/1602.08952},
	abstract = {We present novel methods for analysing the activation patterns of RNNs and identifying the types of linguistic structure they learn. As a case study, we use a multi-task gated recurrent network model consisting of two parallel pathways with shared word embeddings trained on predicting the representations of the visual scene corresponding to an input sentence, and predicting the next word in the same sentence. We show that the image prediction pathway is sensitive to the information structure of the sentence, and pays selective attention to lexical categories and grammatical functions that carry semantic information. It also learns to treat the same input token differently depending on its grammatical functions in the sentence. The language model is comparatively more sensitive to words with a syntactic function. Our analysis of the function of individual hidden units shows that each pathway contains specialized units tuned to patterns informative for the task, some of which can carry activations to later time steps to encode long-term dependencies.},
	urldate = {2016-04-05},
	journal = {arXiv:1602.08952 [cs]},
	author = {{Kádár}, {Ákos} and {Chrupała}, {Grzegorz} and Alishahi, Afra},
	month = feb,
	year = {2016},
	note = {arXiv: 1602.08952},
	keywords = {Computer Science - Learning, Computer Science - Computation and Language},
	file = {arXiv\:1602.08952 PDF:/Users/nsaphra/Documents/zotero/storage/ERDMGIQH/Kádár et al. - 2016 - Representation of linguistic form and function in .pdf:application/pdf;arXiv.org Snapshot:/Users/nsaphra/Documents/zotero/storage/ERB7E5AV/1602.html:text/html}
}

@article{peters2018deep,
  title={Deep contextualized word representations},
  author={Peters, Matthew E and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1802.05365},
  year={2018}
}

@article{DBLP:journals/corr/PressW16,
  author    = {Ofir Press and
               Lior Wolf},
  title     = {Using the Output Embedding to Improve Language Models},
  journal   = {CoRR},
  volume    = {abs/1608.05859},
  year      = {2016},
  url       = {http://arxiv.org/abs/1608.05859},
  archivePrefix = {arXiv},
  eprint    = {1608.05859},
  timestamp = {Mon, 13 Aug 2018 16:48:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/PressW16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

